{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Azure Machine Learning training pipeline\n",
    "\n",
    "This notebook shows the way how to create an AML pipeline for clustering model training. It consists of the following steps:\n",
    "1. AML environment setup \n",
    "2. Pipeline configuration preparation \n",
    "3. Pipeline creation\n",
    "4. Pipeline run\n",
    "\n",
    "The training step will also register the resulting model in the AML workspace as an artifact. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os\n",
    "from os.path import join\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from azureml.core import Environment, Datastore, Workspace, Experiment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "from mlops.common.attach_compute import get_compute\n",
    "from mlops.common.get_datastores import get_blob_datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "interactive_auth = InteractiveLoginAuthentication(tenant_id=os.getenv(\"TENANT_ID\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore AML workspace from config.json file (can be downloaded through the portal)\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
    "\n",
    "compute_target = get_compute(\n",
    "    workspace=ws,\n",
    "    compute_name=\"trainclust\",\n",
    "    vm_size='Standard_NC6',\n",
    "    vm_priority='lowpriority', \n",
    "    min_nodes=0,\n",
    "    max_nodes=4,\n",
    "    scale_down=120\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get or register a datastore (blob with our data)\n",
    "datastore = get_blob_datastore(ws, \"data\", os.getenv(\"AML_BLOB_ACCOUNT_NAME\"), \n",
    "                               os.getenv(\"AML_BLOB_ACCOUNT_KEY\"), \"oneweek-sample-dataset\")\n",
    "\n",
    "# Create input and output data references\n",
    "# WARNING! DataReference works up to 12x times faster than Dataset for small files\n",
    "img_dir = DataReference(\n",
    "    datastore=datastore, \n",
    "    data_reference_name=\"books\", \n",
    "    path_on_datastore=\"books\",\n",
    "    mode=\"mount\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build task-specific environment\n",
    "\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "# Create Pipeline run configuration \n",
    "\n",
    "run_config = RunConfiguration()\n",
    "run_config.environment.docker.enabled = True\n",
    "run_config.environment.python.conda_dependencies = CondaDependencies.create(\n",
    "    pip_packages=[\n",
    "        'azureml-sdk==1.15.0',\n",
    "        'numpy==1.18.5',\n",
    "        'pandas==1.1.3',\n",
    "        'pillow==7.2.0',\n",
    "        'pyarrow==1.0.1',\n",
    "        'scikit-image==0.17.2',\n",
    "        'scikit-learn==0.23.2',\n",
    "        'scipy==1.5.2',\n",
    "        'tqdm==4.48.2',\n",
    "        'opencv-python-headless',\n",
    "        'tensorflow==2.3.0',\n",
    "        'PyYAML==5.3.1'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Custom Vision scoring step\n",
    "\n",
    "source_directory = '../'\n",
    "\n",
    "train_step = PythonScriptStep(\n",
    "    script_name=\"mlops/clustering_pipeline/steps/train.py\", \n",
    "    arguments=[\n",
    "        \"--input_dir\", img_dir,\n",
    "        \"--fraction\", 1.0, # fraction of the dataset\n",
    "        \"--recursive\", False,\n",
    "        \"--eps\", 0.64,\n",
    "        \"--min_samples\", 3,\n",
    "        \"--metric\", \"cosine\",\n",
    "        \"--model_name\", \"dbscan_test\"\n",
    "    ],\n",
    "    inputs=[img_dir],\n",
    "    compute_target=compute_target, \n",
    "    source_directory=source_directory,\n",
    "    runconfig=run_config\n",
    ")\n",
    "\n",
    "# Create pipeline using existing steps\n",
    "train_pipeline = Pipeline(workspace=ws, steps=[train_step])\n",
    "\n",
    "# Check if the pipeline is consistent \n",
    "train_pipeline.validate()\n",
    "\n",
    "# Publish pipeline\n",
    "published_pipeline = train_pipeline.publish(\n",
    "    name = \"similarity_train\",\n",
    "    description = \"Pipeline to train a similarity model for a custom Azure Search skill\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit the pipeline\n",
    "pipeline_run = Experiment(ws, 'similarity-train-exp').submit(train_pipeline)\n",
    "pipeline_run.wait_for_completion()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oneweek1",
   "language": "python",
   "name": "oneweek1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
