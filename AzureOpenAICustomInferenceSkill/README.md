# Azure Open AI Custom Inference Skill

Welcome to the Azure Open AI Custom Inference Skill repository! This guide helps you understand how to leverage Azure OpenAI services using Azure Functions to create a custom inference skill that performs tasks like summarization, entity recognition, and image captioning.

## üöÄ Quickstart Guide

### Prerequisites

- An **Azure OpenAI Deployed Model**, either `gpt-4o` or `gpt-4o-mini`. You can follow [this guide](https://learn.microsoft.com/azure/ai-studio/how-to/deploy-models-openai) to deploy your model. Note, at this time the code will only work with structured outputs as Azure OpenAI only supports `gpt-4o`.

### Important Note on Structured Outputs

As of **11/7/2024**, only the following applies:

- **Supported Models**: Currently, only `gpt-4o` version `2024-08-06` supports structured outputs. However, you can modify the code to remove structured outputs if you want to use it with an older model version or `gpt-4o-mini`.

- **API Support**: Support for structured outputs was first added in API version `2024-08-01-preview`.

### Setup Steps

1. **Clone the Repository**
   - Clone this repository to your local environment to get started.

2. **Configure Environment Variables**
   - In the `local.settings.json` file, set the following:
     - `AZURE_INFERENCE_CREDENTIAL`: Set this value to the API key of your deployed model.
     - `AZURE_CHAT_COMPLETION_ENDPOINT`: Set this to the URL where your model is hosted.

3. **Install Azure Functions Core Tools**
   - To run this function locally, install the Azure Functions Visual Studio extension and update the core tools. Follow the [Azure Functions Python Quickstart Guide](https://learn.microsoft.com/en-us/azure/azure-functions/create-first-function-cli-python?tabs=windows%2Cbash%2Cazure-cli%2Cbrowser) to set up your environment.

4. **Start the Azure Function**
   - Navigate to the folder and run `func start` to initiate the function locally.

5. **Test the API Locally**
   - Use the `api-test.http` file to test the function locally. Replace the `localHostBaseUrl` variable with the base URL of your local environment. Install the Visual Studio REST Client extension to make testing easier by clicking the **Send Request** button.

### üõ†Ô∏è Current Custom Skills
- **Summarization**: Generates a concise summary from the input text.
- **Entity Recognition**: Identifies entities such as people, places, and organizations from the input text.
- **Image Captioning**: Provides a descriptive caption for an image provided either via a URL or as base64-encoded data.

### üñ•Ô∏è Running in Azure
When ready to deploy, you can follow [this guide](https://learn.microsoft.com/en-us/azure/azure-functions/create-first-function-cli-python?tabs=windows%2Cbash%2Cazure-cli%2Cbrowser#create-supporting-azure-resources-for-your-function) to set up your Azure Function resources.

## üåü Use Cases
This function demonstrates how to extend Azure OpenAI models for various natural language processing tasks. It can be used to:

- üìù **Automate Content Creation**: Summarize long texts for automated content creation.
- üîç **Data Extraction**: Extract useful information from unstructured data.
- üñºÔ∏è **Visual Content Analysis**: Automatically generate captions for images, useful in content management systems.

## üîß Extending the Function
You can modify this function to add more scenarios or support other Large Language Models (LLMs). For example:

- **Add New Skills**: Add more scenarios like **text classification** or **sentiment analysis** by modifying the `ScenarioType` and adding new handling logic in the `prepare_messages` function.
- **Swap Models**: Replace the deployed model with another capable model from Azure AI Studio that fits your use case.

## ‚ùì FAQ

### How do I add a new skill to the function?
To add a new skill, update the `ScenarioType` enumeration with a new value and extend the `prepare_messages()` function to handle the new scenario appropriately.

### Can I use models other than `gpt-4o`?
Yes, you can replace the deployed model with any suitable model from Azure AI Studio. Make sure to update the endpoint and model name in your `local.settings.json` file. If using an older model version or `gpt-4o-mini`, consider modifying the code to disable structured outputs.

### How do I use Azure AI Studio models?
For other models that Azure AI Studio offers, simply change the **deployment name** and **endpoint URL** in the configuration to the desired model, ensuring compatibility with the tasks.

## üìö Documentation
- [Azure OpenAI Service Documentation](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/)
- [Azure Functions Documentation](https://learn.microsoft.com/en-us/azure/azure-functions/)

## üõ†Ô∏è Technologies Used
- **Python**
- **Azure Functions**
- **Azure AI Studio**

---

Feel free to explore, modify, and extend the functionality as needed for your use case. If you have questions or suggestions, don't hesitate to open an issue or contribute to the repository!
